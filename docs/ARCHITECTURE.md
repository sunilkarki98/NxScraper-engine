# ScrapeX Architecture: Clean Separation

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ScrapeX SaaS Platform (website/)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Admin Dashboard (Next.js)                  â”‚   â”‚
â”‚  â”‚  - PostgreSQL (users, billing, analytics)   â”‚   â”‚
â”‚  â”‚  - User authentication                      â”‚   â”‚
â”‚  â”‚  - Subscription management                  â”‚   â”‚
â”‚  â”‚  - Job history & reporting                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚ HTTP REST API                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ScrapeX Engine (Pure Scraping Engine)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  API Layer                                   â”‚  â”‚
â”‚  â”‚  /api/v1/scrape     - Submit jobs           â”‚  â”‚
â”‚  â”‚  /api/v1/jobs/:id   - Get status            â”‚  â”‚
â”‚  â”‚  /api/v1/keys/*     - Key management        â”‚  â”‚
â”‚  â”‚  /api/v1/ai/*       - AI endpoints          â”‚  â”‚
â”‚  â”‚  /health, /metrics  - Monitoring            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  DragonflyDB (In-Memory)                     â”‚  â”‚
â”‚  â”‚  - API key hashes (fast auth)                â”‚  â”‚
â”‚  â”‚  - Job queue (BullMQ)                        â”‚  â”‚
â”‚  â”‚  - Scraping cache                            â”‚  â”‚
â”‚  â”‚  - No persistent storage                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
NxScraper-engine/
â”‚
â”œâ”€â”€ core-engine/           â† Pure Scraping Engine
â”‚   â”œâ”€â”€ src/api/          
â”‚   â”‚   â”œâ”€â”€ routes/       â† REST API endpoints
â”‚   â”‚   â”œâ”€â”€ controllers/  â† Business logic
â”‚   â”‚   â””â”€â”€ middleware/   â† Auth, rate limiting
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ shared/               â† Engine internals
â”‚   â”œâ”€â”€ ai/              â† LLM integration
â”‚   â”œâ”€â”€ scrapers/        â† Scraper plugins
â”‚   â”œâ”€â”€ queue/           â† Job queue (BullMQ)
â”‚   â””â”€â”€ database/        â† DragonflyDB client
â”‚
â”œâ”€â”€ services/            â† Scraper implementations
â”‚   â”œâ”€â”€ heavy-scraper/
â”‚   â”œâ”€â”€ google-scraper/
â”‚   â””â”€â”€ universal-scraper/
â”‚
â””â”€â”€ website/             â† SaaS Admin Layer (SEPARATE)
    â”œâ”€â”€ app/admin/       â† Admin UI
    â”œâ”€â”€ lib/
    â”‚   â”œâ”€â”€ db/          â† PostgreSQL (admin data)
    â”‚   â””â”€â”€ engine-api.ts â† API client to call engine
    â””â”€â”€ package.json
```

## ğŸ”Œ API Contract (Engine Interface)

### **Scraping**
```typescript
POST /api/v1/scrape
Authorization: Bearer {api_key}
{
  "url": "https://example.com",
  "scraperType": "heavy-scraper"
}
â†’ Returns: { jobId: "job_abc123" }

GET /api/v1/jobs/{jobId}
â†’ Returns: { status, result, error }
```

### **Key Management**
```typescript
POST /api/v1/keys/internal
{ "userId": "user_123", "tier": "pro" }
â†’ Returns: { key: "nx_pk_prod_..." }

DELETE /api/v1/keys/internal/{keyId}
â†’ Revokes key
```

### **Health & Metrics**
```typescript
GET /health
â†’ { status: "healthy", scrapers: {...} }

GET /metrics  
â†’ Prometheus format
```

## ğŸ¯ Key Principles

### **Engine (core-engine/)**
- âœ… Stateless - No persistent database
- âœ… DragonflyDB only - For cache & queue
- âœ… API-first - Clean REST interface
- âœ… Standalone - Can run without admin
- âœ… Scalable - Horizontal scaling
- âœ… Open-sourceable - No SaaS logic

### **Admin/SaaS (website/)**
- âœ… PostgreSQL - For users, billing, history
- âœ… Next.js - Frontend + API routes
- âœ… Calls engine via HTTP - Loose coupling
- âœ… Owns user management - Auth & billing
- âœ… Stores results - Job history in PG

## ğŸ”„ Data Flow

### Example: User submits scrape job

```
1. User â†’ Admin UI (/admin)
2. Admin â†’ PostgreSQL: Save job request
3. Admin â†’ Engine API: POST /api/v1/scrape
4. Engine â†’ DragonflyDB: Queue job
5. Engine â†’ Worker: Process job
6. Worker â†’ DragonflyDB: Store result (temp)
7. Engine â†’ Admin: Return jobId
8. Admin â†’ Engine API: GET /api/v1/jobs/{jobId}
9. Admin â†’ PostgreSQL: Save result permanently
10. Admin â†’ User: Display result
```

## ğŸš€ Deployment

### **Option 1: Monorepo (Current)**
```bash
# Both run from same repo
docker-compose up -d
```

### **Option 2: Separate Repos**
```bash
# Engine repo
github.com/you/scrapex-engine

# Admin repo  
github.com/you/scrapex-admin
```

## ğŸ’¡ Benefits

1. **Clean Separation** - Engine has zero SaaS logic
2. **Flexibility** - Use engine standalone or with admin
3. **Scalability** - Scale engine and admin independently
4. **Open Source** - Engine can be open-sourced
5. **Multi-tenant** - One engine, multiple admin instances

## ğŸ“ Best Practices

- Engine never knows about users/billing
- Admin never knows about scraping internals
- All communication via REST API
- Engine uses DragonflyDB for speed
- Admin uses PostgreSQL for persistence
