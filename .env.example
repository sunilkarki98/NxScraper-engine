# ==========================================
# ScrapeX Engine - Environment Configuration
# ==========================================
# Copy this file to .env and fill in your actual values
# Do NOT commit .env to version control!

# ==========================================
# Server Configuration
# ==========================================
PORT=3000
NODE_ENV=development
HOST=localhost

# ==========================================
# Redis Configuration (Required)
# ==========================================
# DragonflyDB (Redis-compatible)
DRAGONFLY_URL=redis://localhost:6379
# REQUIRED: Generate with: openssl rand -hex 32
SESSION_ENCRYPTION_KEY=
REDIS_PASSWORD=
REDIS_DB=0
REDIS_TLS=false


# ==========================================
# Security & Authentication
# ==========================================
# Generate a strong random string for JWT_SECRET
# REQUIRED: Generate with: openssl rand -hex 32
JWT_SECRET=
API_KEY_PREFIX=nx_pk_

# Rate Limiting
RATE_LIMIT_WINDOW_MS=60000
RATE_LIMIT_MAX_REQUESTS=100

# ==========================================
# AI Provider API Keys
# ==========================================

# DeepSeek (https://platform.deepseek.com/)
DEEPSEEK_API_KEY=

# Google Gemini LLM (https://makersuite.google.com/app/apikey)
GEMINI_API_KEY=


# Anthropic Claude (https://console.anthropic.com/)
ANTHROPIC_API_KEY=

# OpenAI (https://platform.openai.com/api-keys)
OPENAI_API_KEY=

# OpenRouter (https://openrouter.ai/)
OPENROUTER_API_KEY=



# Ollama (Local/Self-hosted)
# Only set this if you are running Ollama
# OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# ==========================================
# Scraping Configuration
# ==========================================

# Default scraper settings
DEFAULT_SCRAPER_TYPE=heavy-scraper
DEFAULT_TIMEOUT_MS=30000
MAX_RETRIES=3

# Browser settings
HEADLESS=true
DISABLE_IMAGES=true
DISABLE_CSS=false
# REQUIRED: WebSocket endpoint for remote browser (e.g. ws://browserless:3000)
BROWSER_WS_ENDPOINT=ws://browserless:3000

# Worker Thread Configuration (Piscina)
MAX_WORKER_THREADS=4

# Proxy Configuration (Optional)
PROXY_ENABLED=false
PROXY_HOST=
PROXY_PORT=
PROXY_USERNAME=
PROXY_PASSWORD=

#for g-scraper
GOOGLE_API_KEY=

# ==========================================
# Job Queue Configuration
# ==========================================

# BullMQ settings
QUEUE_CONCURRENCY=5
QUEUE_MAX_JOBS=1000
QUEUE_REMOVE_ON_COMPLETE=100
QUEUE_REMOVE_ON_FAIL=1000

# Job timeouts
JOB_TIMEOUT_MS=120000
JOB_ATTEMPTS=3

# ==========================================
# Circuit Breaker Configuration
# ==========================================

# AI Services
AI_CIRCUIT_FAILURE_THRESHOLD=5
AI_CIRCUIT_COOLDOWN_MS=60000

# Scraper Services
SCRAPER_CIRCUIT_FAILURE_THRESHOLD=3
SCRAPER_CIRCUIT_COOLDOWN_MS=30000

# ==========================================
# Caching Configuration
# ==========================================

CACHE_ENABLED=true
CACHE_TTL_SECONDS=3600
CACHE_MAX_SIZE_MB=100

# ==========================================
# Monitoring & Logging
# ==========================================

# Log level: error, warn, info, debug, trace
LOG_LEVEL=info
LOG_PRETTY=true

# Metrics
METRICS_ENABLED=true
METRICS_PORT=9090

# Sentry (Error tracking)
SENTRY_DSN=
SENTRY_ENVIRONMENT=development

# ==========================================
# CORS Configuration
# ==========================================

CORS_ORIGIN=http://localhost:3001
CORS_CREDENTIALS=true

# ==========================================
# Feature Flags
# ==========================================

ENABLE_AI_SCRAPING=true
ENABLE_SCREENSHOT=true
ENABLE_PDF_GENERATION=false
ENABLE_WEBHOOK_NOTIFICATIONS=false

# ==========================================
# Email Configuration (Optional)
# ==========================================

SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_SECURE=false
SMTP_USER=
SMTP_PASSWORD=
EMAIL_FROM=noreply@scrapex.com

# ==========================================
# Webhook Configuration
# ==========================================

WEBHOOK_ENABLED=false
WEBHOOK_SIGNING_SECRET=

# ==========================================
# Development & Testing
# ==========================================

# Skip authentication in development
DEV_SKIP_AUTH=false

# Test API key (dev only)
DEV_API_KEY=

# Mock AI responses (for testing without API keys)
MOCK_AI_RESPONSES=false

# ==========================================
# Production Optimizations
# ==========================================

# Compression
COMPRESSION_ENABLED=true
COMPRESSION_THRESHOLD=1024

# Trust proxy
TRUST_PROXY=false

# Cluster mode
CLUSTER_MODE=false
CLUSTER_WORKERS=4

# REQUIRED: Admin secret for managing API keys (generate strong random string)
# Generate with: openssl rand -base64 32
ADMIN_SECRET=
